<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Emotion Chatbot</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            width: 100%;
            max-width: 800px;
            padding: 30px;
            animation: fadeIn 0.8s ease-out;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(30px); }
            to { opacity: 1; transform: translateY(0); }
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .chat-container {
            height: 400px;
            border: 2px solid #e0e0e0;
            border-radius: 15px;
            padding: 20px;
            overflow-y: auto;
            margin-bottom: 20px;
            background: #f8f9fa;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 18px;
            border-radius: 18px;
            max-width: 80%;
            animation: slideIn 0.3s ease-out;
        }

        @keyframes slideIn {
            from { opacity: 0; transform: translateX(-20px); }
            to { opacity: 1; transform: translateX(0); }
        }

        .user-message {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .bot-message {
            background: #e3f2fd;
            color: #333;
            border: 1px solid #bbdefb;
            position: relative;
        }

        .bot-message.speaking {
            background: #e8f5e8;
            border-color: #4caf50;
        }

        .bot-message .speaking-indicator {
            position: absolute;
            top: 8px;
            right: 8px;
            width: 10px;
            height: 10px;
            background: #4caf50;
            border-radius: 50%;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.5; transform: scale(1.1); }
            100% { opacity: 1; transform: scale(1); }
        }

        .emotion-info {
            font-size: 0.8em;
            margin-top: 5px;
            opacity: 0.8;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .record-btn {
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 50px;
            font-size: 1.1em;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(255, 107, 107, 0.3);
            min-width: 150px;
        }

        .record-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(255, 107, 107, 0.4);
        }

        .record-btn:active {
            transform: translateY(0);
        }

        .record-btn.recording {
            background: linear-gradient(45deg, #45b7d1, #96c93d);
            animation: pulse 1.5s infinite;
        }

        .record-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .stats-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .stats-card {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .stats-card h3 {
            margin-bottom: 10px;
            font-size: 1.2em;
        }

        .status {
            text-align: center;
            margin: 10px 0;
            padding: 10px;
            border-radius: 10px;
            font-weight: bold;
        }

        .status.processing {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.speaking {
            background: #e8f5e8;
            color: #2e7d32;
            border: 1px solid #81c784;
        }

        .emotion-indicator {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 0.8em;
            font-weight: bold;
            margin-left: 10px;
        }

        .emotion-happy { background: #fff3cd; color: #856404; }
        .emotion-sad { background: #d1ecf1; color: #0c5460; }
        .emotion-angry { background: #f8d7da; color: #721c24; }
        .emotion-fearful { background: #e2e3e5; color: #383d41; }
        .emotion-surprised { background: #ffeaa7; color: #8e6a00; }
        .emotion-disgust { background: #f0d0d0; color: #7a4848; }
        .emotion-calm { background: #d4edda; color: #155724; }
        .emotion-neutral { background: #e9ecef; color: #495057; }

        .audio-controls {
            margin-top: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .volume-control {
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 0.9em;
        }

        .volume-slider {
            width: 80px;
        }

        .loading-spinner {
            display: none;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            width: 30px;
            height: 30px;
            animation: spin 1s linear infinite;
            margin: 0 auto;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .microphone-icon {
            margin-right: 8px;
        }

        .settings-panel {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 20px;
        }

        .settings-panel h3 {
            margin-bottom: 10px;
            color: #333;
        }

        .setting-item {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 10px;
        }

        .setting-item label {
            font-size: 0.9em;
            color: #555;
        }

        .toggle-switch {
            position: relative;
            width: 50px;
            height: 24px;
            background: #ccc;
            border-radius: 12px;
            cursor: pointer;
            transition: background 0.3s;
        }

        .toggle-switch.active {
            background: #4caf50;
        }

        .toggle-switch::before {
            content: '';
            position: absolute;
            top: 2px;
            left: 2px;
            width: 20px;
            height: 20px;
            background: white;
            border-radius: 50%;
            transition: transform 0.3s;
        }

        .toggle-switch.active::before {
            transform: translateX(26px);
        }

        @media (max-width: 600px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            .controls {
                flex-direction: column;
                align-items: center;
            }
            
            .record-btn {
                width: 100%;
                max-width: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 Voice Emotion Chatbot</h1>
        
        <div class="settings-panel">
            <h3>Voice Settings</h3>
            <div class="setting-item">
                <label>Auto-speak responses</label>
                <div class="toggle-switch active" id="autoSpeakToggle" onclick="toggleAutoSpeak()"></div>
            </div>
            <div class="setting-item">
                <label>Voice volume</label>
                <div class="volume-control">
                    <span>🔊</span>
                    <input type="range" id="volumeSlider" class="volume-slider" min="0" max="1" step="0.1" value="0.8" onchange="updateVolume()">
                    <span id="volumeDisplay">80%</span>
                </div>
            </div>
        </div>
        
        <div class="chat-container" id="chatContainer">
            <div class="bot-message">
                <div>Hello! I'm your emotion-aware voice assistant. Click the record button to start our conversation. I can understand your emotions and respond accordingly! 😊</div>
            </div>
        </div>

        <div class="status" id="status" style="display: none;"></div>
        <div class="loading-spinner" id="loadingSpinner"></div>

        <div class="controls">
            <button class="record-btn" id="recordBtn" onclick="toggleRecording()">
                <span class="microphone-icon">🎤</span>
                <span id="recordText">Start Recording</span>
            </button>
            <button class="record-btn" onclick="clearChat()" style="background: linear-gradient(45deg, #74b9ff, #0984e3);">
                🗑️ Clear Chat
            </button>
            <button class="record-btn" onclick="loadStats()" style="background: linear-gradient(45deg, #a29bfe, #6c5ce7);">
                📊 Show Stats
            </button>
        </div>

        <div class="stats-container" id="statsContainer" style="display: none;">
            <div class="stats-card">
                <h3>Emotions Detected</h3>
                <div id="emotionStats">Loading...</div>
            </div>
            <div class="stats-card">
                <h3>Sentiment Analysis</h3>
                <div id="sentimentStats">Loading...</div>
            </div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let autoSpeakEnabled = true;
        let currentVolume = 0.8;
        let currentSpeechAudio = null;
        let currentBotMessage = null;

        function showStatus(message, type) {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status ${type}`;
            status.style.display = 'block';
            
            if (type === 'success' || type === 'error') {
                setTimeout(() => {
                    status.style.display = 'none';
                }, 3000);
            }
        }

        function showLoading(show) {
            document.getElementById('loadingSpinner').style.display = show ? 'block' : 'none';
        }

        function toggleAutoSpeak() {
            autoSpeakEnabled = !autoSpeakEnabled;
            const toggle = document.getElementById('autoSpeakToggle');
            toggle.classList.toggle('active', autoSpeakEnabled);
            
            if (autoSpeakEnabled) {
                showStatus('Auto-speak enabled', 'success');
            } else {
                showStatus('Auto-speak disabled', 'success');
                // Stop current speech if any
                if (currentSpeechAudio) {
                    currentSpeechAudio.pause();
                    currentSpeechAudio = null;
                }
                if (currentBotMessage) {
                    currentBotMessage.classList.remove('speaking');
                    const indicator = currentBotMessage.querySelector('.speaking-indicator');
                    if (indicator) indicator.remove();
                }
            }
        }

        function updateVolume() {
            const slider = document.getElementById('volumeSlider');
            const display = document.getElementById('volumeDisplay');
            currentVolume = parseFloat(slider.value);
            display.textContent = Math.round(currentVolume * 100) + '%';
            
            // Update current audio if playing
            if (currentSpeechAudio) {
                currentSpeechAudio.volume = currentVolume;
            }
        }

        function playBotResponse(audioBase64, messageElement) {
            if (!autoSpeakEnabled || !audioBase64) return;

            try {
                // Stop any currently playing audio
                if (currentSpeechAudio) {
                    currentSpeechAudio.pause();
                    currentSpeechAudio = null;
                }

                // Remove speaking indicator from previous message
                if (currentBotMessage) {
                    currentBotMessage.classList.remove('speaking');
                    const prevIndicator = currentBotMessage.querySelector('.speaking-indicator');
                    if (prevIndicator) prevIndicator.remove();
                }

                // Create audio element
                const audio = new Audio(`data:audio/wav;base64,${audioBase64}`);
                audio.volume = currentVolume;
                
                // Add speaking indicator
                const indicator = document.createElement('div');
                indicator.className = 'speaking-indicator';
                messageElement.appendChild(indicator);
                messageElement.classList.add('speaking');
                
                currentSpeechAudio = audio;
                currentBotMessage = messageElement;
                
                // Show speaking status
                showStatus('🔊 Bot is speaking...', 'speaking');
                
                // Play audio
                audio.play().catch(error => {
                    console.error('Error playing audio:', error);
                    showStatus('Error playing audio response', 'error');
                    messageElement.classList.remove('speaking');
                    indicator.remove();
                });
                
                // Handle audio end
                audio.addEventListener('ended', () => {
                    messageElement.classList.remove('speaking');
                    indicator.remove();
                    currentSpeechAudio = null;
                    currentBotMessage = null;
                    showStatus('Ready for next conversation', 'success');
                });
                
                // Handle audio error
                audio.addEventListener('error', (e) => {
                    console.error('Audio playback error:', e);
                    messageElement.classList.remove('speaking');
                    indicator.remove();
                    currentSpeechAudio = null;
                    currentBotMessage = null;
                    showStatus('Error playing audio response', 'error');
                });
                
            } catch (error) {
                console.error('Error setting up audio playback:', error);
                showStatus('Error setting up audio playback', 'error');
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendAudio(audioBlob);
                    
                    // Stop all tracks to release microphone
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;
                
                const recordBtn = document.getElementById('recordBtn');
                const recordText = document.getElementById('recordText');
                
                recordBtn.classList.add('recording');
                recordText.textContent = 'Stop Recording';
                
                showStatus('Recording... Click again to stop', 'processing');

            } catch (error) {
                console.error('Error accessing microphone:', error);
                showStatus('Error accessing microphone. Please allow microphone access.', 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                const recordBtn = document.getElementById('recordBtn');
                const recordText = document.getElementById('recordText');
                
                recordBtn.classList.remove('recording');
                recordText.textContent = 'Start Recording';
                recordBtn.disabled = true;
                
                showStatus('Processing audio...', 'processing');
                showLoading(true);
            }
        }

        function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        async function sendAudio(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'audio.webm');

            try {
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                showLoading(false);
                document.getElementById('recordBtn').disabled = false;

                if (response.ok) {
                    displayMessage(data.user_text, 'user', data.emotion, data.emotion_confidence, data.sentiment);
                    const botMessageElement = displayMessage(data.bot_response, 'bot', null, null, null, data.audio_response);
                    
                    // Auto-play the bot response
                    if (data.audio_response) {
                        setTimeout(() => playBotResponse(data.audio_response, botMessageElement), 500);
                    }
                    
                    showStatus('Conversation processed successfully!', 'success');
                } else {
                    showStatus(`Error: ${data.error}`, 'error');
                }

            } catch (error) {
                console.error('Error sending audio:', error);
                showLoading(false);
                document.getElementById('recordBtn').disabled = false;
                showStatus('Error processing audio. Please try again.', 'error');
            }
        }

        function displayMessage(text, sender, emotion = null, confidence = null, sentiment = null, audioResponse = null) {
            const chatContainer = document.getElementById('chatContainer');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}-message`;

            let emotionHtml = '';
            if (emotion && sender === 'user') {
                const confidencePercent = Math.round(confidence * 100);
                emotionHtml = `
                    <div class="emotion-info">
                        <span class="emotion-indicator emotion-${emotion}">${emotion}</span>
                        <span>(${confidencePercent}% confidence)</span>
                        ${sentiment ? `| Sentiment: ${sentiment.label} (${sentiment.polarity.toFixed(2)})` : ''}
                    </div>
                `;
            }

            let audioControlsHtml = '';
            if (audioResponse && sender === 'bot') {
                audioControlsHtml = `
                    <div class="audio-controls">
                        <button onclick="playBotResponse('${audioResponse}', this.closest('.message'))" 
                                style="background: #4caf50; color: white; border: none; padding: 5px 10px; border-radius: 15px; cursor: pointer; font-size: 0.8em;">
                            🔊 Replay
                        </button>
                        <span style="font-size: 0.8em; color: #666;">
                            ${autoSpeakEnabled ? '(Auto-played)' : '(Click to play)'}
                        </span>
                    </div>
                `;
            }

            messageDiv.innerHTML = `
                <div>${text}</div>
                ${emotionHtml}
                ${audioControlsHtml}
            `;

            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            
            return messageDiv;
        }

        function clearChat() {
            // Stop any playing audio
            if (currentSpeechAudio) {
                currentSpeechAudio.pause();
                currentSpeechAudio = null;
            }
            if (currentBotMessage) {
                currentBotMessage.classList.remove('speaking');
                const indicator = currentBotMessage.querySelector('.speaking-indicator');
                if (indicator) indicator.remove();
            }
            
            const chatContainer = document.getElementById('chatContainer');
            chatContainer.innerHTML = `
                <div class="bot-message">
                    <div>Hello! I'm your emotion-aware voice assistant. Click the record button to start our conversation. I can understand your emotions and respond accordingly! 😊</div>
                </div>
            `;
            showStatus('Chat cleared!', 'success');
        }

        async function loadStats() {
            const statsContainer = document.getElementById('statsContainer');
            
            if (statsContainer.style.display === 'none') {
                try {
                    const response = await fetch('/emotion_stats');
                    const data = await response.json();

                    if (response.ok) {
                        displayStats(data);
                        statsContainer.style.display = 'grid';
                    } else {
                        showStatus('Error loading stats', 'error');
                    }
                } catch (error) {
                    console.error('Error loading stats:', error);
                    showStatus('Error loading stats', 'error');
                }
            } else {
                statsContainer.style.display = 'none';
            }
        }

        function displayStats(data) {
            const emotionStats = document.getElementById('emotionStats');
            const sentimentStats = document.getElementById('sentimentStats');

            // Display emotion statistics
            let emotionHtml = '';
            if (Object.keys(data.emotions).length > 0) {
                for (const [emotion, stats] of Object.entries(data.emotions)) {
                    emotionHtml += `
                        <div style="margin-bottom: 8px;">
                            <span class="emotion-indicator emotion-${emotion}">${emotion}</span>
                            <div style="font-size: 0.9em; margin-top: 4px;">
                                Count: ${stats.count} | Avg Confidence: ${stats.avg_confidence}%
                            </div>
                        </div>
                    `;
                }
            } else {
                emotionHtml = 'No conversations yet';
            }
            emotionStats.innerHTML = emotionHtml;

            // Display sentiment statistics
            let sentimentHtml = '';
            if (Object.keys(data.sentiments).length > 0) {
                for (const [sentiment, stats] of Object.entries(data.sentiments)) {
                    const bgColor = sentiment === 'positive' ? '#d4edda' : 
                                   sentiment === 'negative' ? '#f8d7da' : '#e9ecef';
                    const textColor = sentiment === 'positive' ? '#155724' :
                                     sentiment === 'negative' ? '#721c24' : '#495057';
                    
                    sentimentHtml += `
                        <div style="margin-bottom: 8px;">
                            <span style="background: ${bgColor}; color: ${textColor}; padding: 4px 8px; border-radius: 12px; font-size: 0.8em; font-weight: bold;">
                                ${sentiment}
                            </span>
                            <div style="font-size: 0.9em; margin-top: 4px;">
                                Count: ${stats.count} | Avg Polarity: ${stats.avg_polarity}
                            </div>
                        </div>
                    `;
                }
                sentimentHtml += `<div style="margin-top: 15px; font-size: 0.9em;">Total Conversations: ${data.total_conversations}</div>`;
            } else {
                sentimentHtml = 'No conversations yet';
            }
            sentimentStats.innerHTML = sentimentHtml;
        }

        // Initialize the app
        document.addEventListener('DOMContentLoaded', function() {
            showStatus('Ready to start conversation! Click "Start Recording" to begin.', 'success');
            
            // Initialize volume display
            updateVolume();
            
            // Auto-speak welcome message if enabled
            if (autoSpeakEnabled) {
                const welcomeMessage = "Hello! I'm your emotion-aware voice assistant. Click the record button to start our conversation.";
                // You can uncomment the next line if you want to speak the welcome message
                // speakText(welcomeMessage);
            }
        });

        // Function to speak text using Web Speech API as fallback
        function speakText(text) {
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.volume = currentVolume;
                utterance.rate = 0.9;
                utterance.pitch = 1;
                
                // Use a more natural voice if available
                const voices = speechSynthesis.getVoices();
                const preferredVoice = voices.find(voice => 
                    voice.lang.includes('en') && voice.name.includes('Female')
                ) || voices.find(voice => voice.lang.includes('en'));
                
                if (preferredVoice) {
                    utterance.voice = preferredVoice;
                }
                
                speechSynthesis.speak(utterance);
            }
        }

        // Keyboard shortcuts
        document.addEventListener('keydown', function(event) {
            if (event.code === 'Space' && !event.target.matches('input, textarea')) {
                event.preventDefault();
                toggleRecording();
            } else if (event.code === 'Escape') {
                // Stop current speech
                if (currentSpeechAudio) {
                    currentSpeechAudio.pause();
                    currentSpeechAudio = null;
                }
                if (currentBotMessage) {
                    currentBotMessage.classList.remove('speaking');
                    const indicator = currentBotMessage.querySelector('.speaking-indicator');
                    if (indicator) indicator.remove();
                }
            }
        });

        // Handle page visibility change to pause audio when tab is hidden
        document.addEventListener('visibilitychange', function() {
            if (document.hidden && currentSpeechAudio) {
                currentSpeechAudio.pause();
            }
        });
    </script>
</body>
</html>
